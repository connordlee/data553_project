{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in all JSON files and adding binary classification columns\n",
    "with open(os.getcwd()+\"/training_data/all.json\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = json.dumps(data)\n",
    "test = json.loads(test)\n",
    "test = pd.DataFrame.from_dict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment', 'rating', 'past', 'stopwords_removal', 'reviewer', 'id',\n",
       "       'stemmed', 'fee', 'title', 'label', 'future', 'lemmatized_comment',\n",
       "       'sentiScore', 'sentiScore_neg', 'reviewId', 'stopwords_removal_nltk',\n",
       "       'present_simple', 'dataSource', 'appId', 'date', 'sentiScore_pos',\n",
       "       'present_con', 'length_words', 'stopwords_removal_lemmatization',\n",
       "       'Exclude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n",
      "295\n"
     ]
    }
   ],
   "source": [
    "with open(os.getcwd()+\"/training_data/Feature.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "test2 = json.dumps(data)\n",
    "test2 = json.loads(test2)\n",
    "test2 = pd.DataFrame.from_dict(test2)\n",
    "print(len(test2))\n",
    "test2 = test2.drop_duplicates(subset=\"id\")\n",
    "print(len(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+\"/training_data/Bug.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "test3 = json.dumps(data)\n",
    "test3 = json.loads(test3)\n",
    "test3 = pd.DataFrame.from_dict(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+\"/training_data/Rating.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "test4 = json.dumps(data)\n",
    "test4 = json.loads(test4)\n",
    "test4 = pd.DataFrame.from_dict(test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+\"/training_data/UserExperience.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "test5 = json.dumps(data)\n",
    "test5 = json.loads(test5)\n",
    "test5 = pd.DataFrame.from_dict(test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3691\n",
      "3734\n"
     ]
    }
   ],
   "source": [
    "print(len(test))\n",
    "print(len(test2)+len(test3)+len(test4)+len(test5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2[\"Feature\"] = 1\n",
    "test3[\"Bug\"] = 1\n",
    "test4[\"Rating\"] = 1\n",
    "test5[\"UserExperience\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3691\n",
      "3734\n",
      "3734\n"
     ]
    }
   ],
   "source": [
    "print(len(test))\n",
    "print(len(test2)+len(test3)+len(test4)+len(test5))\n",
    "print(test2[\"Feature\"].sum()+test3[\"Bug\"].sum()+test4[\"Rating\"].sum()+test5[\"UserExperience\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(test2[[\"comment\",\"date\",\"Feature\"]], on=[\"comment\",\"date\"], how=\"left\")\n",
    "test = test.merge(test3[[\"comment\",\"date\",\"Bug\"]], on=[\"comment\",\"date\"], how=\"left\")\n",
    "test = test.merge(test4[[\"comment\",\"date\",\"Rating\"]], on=[\"comment\",\"date\"], how=\"left\")\n",
    "test = test.merge(test5[[\"comment\",\"date\",\"UserExperience\"]], on=[\"comment\",\"date\"], how=\"left\")\n",
    "test = test.fillna(0)\n",
    "test = test.drop_duplicates()\n",
    "test[\"comment\"] = test[\"comment\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>stopwords_removal</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>id</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>fee</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>present_con</th>\n",
       "      <th>length_words</th>\n",
       "      <th>stopwords_removal_lemmatization</th>\n",
       "      <th>Exclude</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Bug</th>\n",
       "      <th>Rating</th>\n",
       "      <th>UserExperience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4316</td>\n",
       "      <td>loved this app from jump!\\thave never had any ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>loved this app from jump! have never had any i...</td>\n",
       "      <td>0</td>\n",
       "      <td>733</td>\n",
       "      <td>lov thi ap from jump! hav nev had any issu wit...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>love this app from jump! have never have any i...</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4317</td>\n",
       "      <td>best app\\tcan always edit my pics and they wil...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>best app can always edit pics will end well</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "      <td>best ap can alway edit my pic and they wil end...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>best app can always edit pic will end well</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4318</td>\n",
       "      <td>awesome\\tpics art is my only app for editing</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>awesome pics art only app for editing</td>\n",
       "      <td>0</td>\n",
       "      <td>735</td>\n",
       "      <td>awesom pic art is my on ap for edit</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>awesome pic art only app for edit</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4319</td>\n",
       "      <td>5star!!!!!\\ti love it! ! sumtime hate it catch...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5star!!!!! love it! ! sumtime hate catch editi...</td>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>5star!!!!! i lov it! ! sumtim hat it catch mys...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5star!!!!! love it! ! sumtime hate catch edit ...</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>favourite hands down for photo editing ?\\teasy...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>favourite hands for photo editing ? easy to us...</td>\n",
       "      <td>0</td>\n",
       "      <td>737</td>\n",
       "      <td>favourit hand down for photo edit ? easy to us...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>UserExperience</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>favourite hand for photo edit ? easy to use sm...</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  rating  past  \\\n",
       "4316  loved this app from jump!\\thave never had any ...       5     3   \n",
       "4317  best app\\tcan always edit my pics and they wil...       5     0   \n",
       "4318       awesome\\tpics art is my only app for editing       3     0   \n",
       "4319  5star!!!!!\\ti love it! ! sumtime hate it catch...       5     0   \n",
       "4320  favourite hands down for photo editing ?\\teasy...       5     0   \n",
       "\n",
       "                                      stopwords_removal reviewer   id  \\\n",
       "4316  loved this app from jump! have never had any i...        0  733   \n",
       "4317        best app can always edit pics will end well        0  734   \n",
       "4318              awesome pics art only app for editing        0  735   \n",
       "4319  5star!!!!! love it! ! sumtime hate catch editi...        0  736   \n",
       "4320  favourite hands for photo editing ? easy to us...        0  737   \n",
       "\n",
       "                                                stemmed fee title  \\\n",
       "4316  lov thi ap from jump! hav nev had any issu wit...   0         \n",
       "4317  best ap can alway edit my pic and they wil end...   0         \n",
       "4318                awesom pic art is my on ap for edit   0         \n",
       "4319  5star!!!!! i lov it! ! sumtim hat it catch mys...   0         \n",
       "4320  favourit hand down for photo edit ? easy to us...   0         \n",
       "\n",
       "               label  ...  date sentiScore_pos  present_con  length_words  \\\n",
       "4316  UserExperience  ...     0              4            0            37   \n",
       "4317  UserExperience  ...     0              2            0            13   \n",
       "4318  UserExperience  ...     0              3            0             9   \n",
       "4319  UserExperience  ...     0              3            1            35   \n",
       "4320  UserExperience  ...     0              2            1            16   \n",
       "\n",
       "                        stopwords_removal_lemmatization Exclude  Feature  Bug  \\\n",
       "4316  love this app from jump! have never have any i...       \u0000      0.0  0.0   \n",
       "4317         best app can always edit pic will end well       \u0000      0.0  0.0   \n",
       "4318                  awesome pic art only app for edit       \u0000      0.0  0.0   \n",
       "4319  5star!!!!! love it! ! sumtime hate catch edit ...       \u0000      0.0  0.0   \n",
       "4320  favourite hand for photo edit ? easy to use sm...       \u0000      0.0  0.0   \n",
       "\n",
       "     Rating UserExperience  \n",
       "4316    0.0            1.0  \n",
       "4317    0.0            1.0  \n",
       "4318    0.0            1.0  \n",
       "4319    0.0            1.0  \n",
       "4320    0.0            1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3691, 5665)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of Words (BOW)\n",
    "count_vect = CountVectorizer()\n",
    "bow = count_vect.fit_transform(test[\"comment\"])\n",
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3691, 5533)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BOW - Stop Words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "count_vect = CountVectorizer(stop_words=stop_words)\n",
    "bowStop = count_vect.fit_transform(test[\"comment\"])\n",
    "bowStop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams Function\n",
    "def tokenize(commentSeries):\n",
    "    tokens = [token for token in commentSeries.split(\" \") if token != \"\"]\n",
    "    output = list(ngrams(tokens, 2))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams\n",
    "bigrams = test.copy()\n",
    "bigrams[\"comment\"] = bigrams[\"comment\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams Function - Stop Words\n",
    "def tokenizeStop(commentSeries):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in commentSeries.split(\" \") if (token != \"\" and token not in stop_words)]\n",
    "    output = list(ngrams(tokens, 2))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams - Stop Words\n",
    "bigramsStop = test.copy()\n",
    "bigramsStop[\"comment\"] = bigramsStop[\"comment\"].apply(tokenizeStop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>past</th>\n",
       "      <th>stopwords_removal</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>id</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>fee</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiScore_pos</th>\n",
       "      <th>present_con</th>\n",
       "      <th>length_words</th>\n",
       "      <th>stopwords_removal_lemmatization</th>\n",
       "      <th>Exclude</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Bug</th>\n",
       "      <th>Rating</th>\n",
       "      <th>UserExperience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[(besides, occasional), (occasional, crash,), ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>besides occasional crash, this amazing product...</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>besid the occa crash, thi is an amaz produc wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Almost perfect</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>besides occasional crash, this amaze product w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[(could, great), (great, app), (app, predictab...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>this could be great app if was predictable, bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>thi could be a gre ap if it was predictable, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>Take a photo of your boarding pass</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>this could be great app if be predictable, but...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[(can't, open), (open, since), (since, last), ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>can't open since last 2 updates pop-ups go cra...</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>i can't op sint the last 2 upd pop-ups go craz...</td>\n",
       "      <td>0</td>\n",
       "      <td>Won't open due to pop-ups since upgrade</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>can't open since last 2 update pop-up go crazy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[(use, love), (love, app), (app, working), (wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>use to love this app but its not working after...</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>us to lov thi ap but its not work aft new upda...</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Working After Update</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>use to love this app but its not work after ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[(urrrrm\\tafter, third), (third, installing,),...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>urrrrm after third re installing, finally has ...</td>\n",
       "      <td>cid-gp:AOqpTOE3YjNzLOttARdiYx3b2O02-B1k-FO01WO...</td>\n",
       "      <td>13</td>\n",
       "      <td>urrrrm aft my third re installing, it fin has ...</td>\n",
       "      <td>paid</td>\n",
       "      <td>0</td>\n",
       "      <td>Bug</td>\n",
       "      <td>...</td>\n",
       "      <td>12:44</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>urrrrm after third re installing, finally have...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  rating  past  \\\n",
       "0  [(besides, occasional), (occasional, crash,), ...       5     0   \n",
       "1  [(could, great), (great, app), (app, predictab...       1     1   \n",
       "2  [(can't, open), (open, since), (since, last), ...       1     0   \n",
       "3  [(use, love), (love, app), (app, working), (wo...       1     1   \n",
       "4  [(urrrrm\\tafter, third), (third, installing,),...       3     5   \n",
       "\n",
       "                                   stopwords_removal  \\\n",
       "0  besides occasional crash, this amazing product...   \n",
       "1  this could be great app if was predictable, bu...   \n",
       "2  can't open since last 2 updates pop-ups go cra...   \n",
       "3  use to love this app but its not working after...   \n",
       "4  urrrrm after third re installing, finally has ...   \n",
       "\n",
       "                                            reviewer   id  \\\n",
       "0                                                  0  264   \n",
       "1                                                  0  111   \n",
       "2                                                  0  210   \n",
       "3                                                  0   53   \n",
       "4  cid-gp:AOqpTOE3YjNzLOttARdiYx3b2O02-B1k-FO01WO...   13   \n",
       "\n",
       "                                             stemmed   fee  \\\n",
       "0  besid the occa crash, thi is an amaz produc wi...     0   \n",
       "1  thi could be a gre ap if it was predictable, b...     0   \n",
       "2  i can't op sint the last 2 upd pop-ups go craz...     0   \n",
       "3  us to lov thi ap but its not work aft new upda...     0   \n",
       "4  urrrrm aft my third re installing, it fin has ...  paid   \n",
       "\n",
       "                                     title label  ...   date sentiScore_pos  \\\n",
       "0                           Almost perfect   Bug  ...      0              3   \n",
       "1       Take a photo of your boarding pass   Bug  ...      0              3   \n",
       "2  Won't open due to pop-ups since upgrade   Bug  ...      0              2   \n",
       "3                 Not Working After Update   Bug  ...      0              3   \n",
       "4                                        0   Bug  ...  12:44              4   \n",
       "\n",
       "   present_con  length_words  \\\n",
       "0            1            22   \n",
       "1            0            58   \n",
       "2            1            24   \n",
       "3            1            39   \n",
       "4            2           150   \n",
       "\n",
       "                     stopwords_removal_lemmatization Exclude  Feature  Bug  \\\n",
       "0  besides occasional crash, this amaze product w...       0      0.0  1.0   \n",
       "1  this could be great app if be predictable, but...       0      0.0  1.0   \n",
       "2  can't open since last 2 update pop-up go crazy...       0      0.0  1.0   \n",
       "3  use to love this app but its not work after ne...       0      0.0  1.0   \n",
       "4  urrrrm after third re installing, finally have...       0      0.0  1.0   \n",
       "\n",
       "  Rating UserExperience  \n",
       "0    1.0            0.0  \n",
       "1    0.0            0.0  \n",
       "2    0.0            0.0  \n",
       "3    0.0            0.0  \n",
       "4    0.0            1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramsStop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lematizing\n",
    "def lemmatizeData(commentSeries):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [token for token in commentSeries.split(\" \") if token != \"\"]\n",
    "    output = ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = test.copy()\n",
    "lemmatized[\"comment\"] = lemmatized[\"comment\"].apply(lemmatizeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    besides the occasional crash, this is an amazi...\n",
       "1    this could be a great app if it wa predictable...\n",
       "2    i can't open since the last 2 update pop-up go...\n",
       "3    use to love this app but it's not working afte...\n",
       "4    urrrrm\\tafter my third re installing, it final...\n",
       "5    this app serf it purpose for me perfectly exce...\n",
       "6    album function need improvement\\tcurrent versi...\n",
       "7    i'm very disappointed that i can't open most e...\n",
       "8    need to be updated.\\twas fun & challenging. de...\n",
       "9    it's good if you want to browse but is horribl...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized[\"comment\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "def stemData(commentSeries):\n",
    "    lancaster = LancasterStemmer()\n",
    "    tokens = [token for token in commentSeries.split(\" \") if token != \"\"]\n",
    "    output = ' '.join([lancaster.stem(word) for word in tokens])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed = test.copy()\n",
    "stemmed[\"comment\"] = stemmed[\"comment\"].apply(stemData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3691, 25235)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigrams + BOW - Stop Words + stemming\n",
    "BBSS = test.copy()\n",
    "BBSS[\"comment\"] = BBSS[\"comment\"].apply(stemData)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "count_vect = CountVectorizer(stop_words=stop_words, ngram_range=(2,2))\n",
    "bowStop = count_vect.fit_transform(BBSS[\"comment\"])\n",
    "bowStop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
